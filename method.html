<!doctype html>
<html>

<head>
  <title>Conditional-GAN based Fair Image Classification</title>
  <meta charset="utf-8" name="viewport" content="width=device-width, initial-scale=1">
  <link href="css/frame.css" media="screen" rel="stylesheet" type="text/css" />
  <link href="css/controls.css" media="screen" rel="stylesheet" type="text/css" />
  <link href="css/custom.css" media="screen" rel="stylesheet" type="text/css" />
  <link href='https://fonts.googleapis.com/css?family=Open+Sans:400,700' rel='stylesheet' type='text/css'>
  <link href='https://fonts.googleapis.com/css?family=Open+Sans+Condensed:300,700' rel='stylesheet' type='text/css'>
  <link href="https://fonts.googleapis.com/css?family=Source+Sans+Pro:400,700" rel="stylesheet">
  <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script src="js/menu.js"></script>
  <style>
    .menu-index {
      color: rgb(255, 255, 255) !important;
      opacity: 1 !important;
      font-weight: 700 !important;
    }
  </style>
</head>
<body>

  <div class="menu-container"></div>
  <div class="content-container">
    <div class="content">
      <div class="content-table flex-column">
        <!--Start Text with Images and Image buttons-->
        <div class="flex-row">
          <div class="flex-item flex-column">
            <h2 class="add-top-margin">Preliminary: StyleGAN</h2>
            <hr>
            <p class="text"><font size=4>
                The "Style" in StyleGAN[1] means low-level attributes of objects, such as head pose and facial expression in the human face dataset. Generally, StyleGAN uses random noise with a uniform or Gaussian distribution as input and generates high-resolution and realistic synthetic images. The StyleGAN is mainly composed of two parts, which are the Mapping network and the Synthesis network. The brief architecture of StyleGAN is shown in Figure 2.
              </font>
            </p>
          </div>
        </div>
        <div class="flex-row-space-between">
          <div class="flex-item flex-column">
            <img class="image max-width-400" src="imgs/stylegan_face.jpeg">
            <p class="image-caption"><font size=2>Figure 1. Synthetic images generated from radnom noise.</font></p>
          </div>
          <div class="flex-item flex-column">
            <img class="image max-width-400" src="imgs/stylegan.png">
            <p class="image-caption"><font size=2>Figure 2. The brief architecture of StyleGAN.</font></p>
          </div>
        </div>
        <div class="flex-row">
          <div class="flex-item flex-column">
            <p class="text"><font size=4>
              <b>Mapping Network</b> The mapping network maps the random noise z to the intermediate latent space W. The goal of the mapping network is to disentangle different attributes. Besides, in the real world, the distribution of different attributes does not necessarily obey a uniform or normal distribution. So we need to map random vector z to another space to simulate the distribution of attributes. After that, we can modify the latent code w to change the attributes of the synthetic faces.
              </font>
            </p>
            <p class="text"><font size=4>
              <b>Synthesis Network</b> The synthesis network generates fake images according to the latent code w. The synthesis network uses affined latent code w and noise as inputs, where the style have global effects (changing pose, identity, etc.), the noise affects only inconsequential stochastic variation (differently combed hair, beard, etc.). As shown in Figure 2, "A" stands for a learned affine transform and "B" applies learned per-channel scaling factor to the noise input.
              </font>
            </p>
          </div>
        </div>
        <!--End Text with Images and Image buttons-->


        <!--Start Text with Images and Image buttons-->
        <div class="flex-row">
          <div class="flex-item flex-column">
            <h2 class="add-top-margin">Style Mixing In the Latent Space</h2>
            <hr>
            <p class="text"><font size=4>
                Low-level attributes are disentangled in the StyleGAN latent space. Specifically, different channels in latent space w roughly control different attributes such as head pose and facial texture [2]. And the generator can generate diverse synthetic images according to different latent codes. One way to generate diverse synthetic images is to mix the image style of two images by mixing their latent codes. For each image pair, we can first project them to the latent space and then get a mixed latent code accordingly.
                </font>
            </p>
          </div>
        </div>
        <div class="flex-row-space-between">
          <div class="flex-item flex-column">
            <img class="image max-width-800" src="imgs/style_mixing.png">
            <p class="image-caption"><font size =2>Figure 3. Example of image style-mixture by latent code channel replacement. The first and the third column are selected image pairs and the middle one is generated image with mixed latent code.</font></p>
          </div>
        </div>
        <div class="flex-row">
          <div class="flex-item flex-column">
            <p class="text"><font size=4>
              As shown in the figures, the first and the third column are selected image pairs and we use the last 11 dimensions of the first image’s latent code and the first 3 dimensions of the third one. In this way, we can generate a fake image with a mixed image style. Then we assign the same label with the first image to the generated image. The synthetic images are visually good. It keeps the ethnicity of the first image and changes some race-unrelated attributes according to the third image.
              </font>
            </p>
          </div>
        </div>
        <!--End Text with Images and Image buttons-->


        <!--Start Text with Images and Image buttons-->
        <div class="flex-row">
          <div class="flex-item flex-column">
            <h2 class="add-top-margin">Conditional-StyleGAN based Dataset Augmentation</h2>
            <hr>
            <p class="text"><font size=4>
                Because race is a high-level attribute and it isn’t disentangled in StyleGAN latent space. We cannot directly sample in the original StyleGAN latent space to generate a race-balanced data pool. Therefore, we modify the StyleGAN architecture and insert the label information to train a Conditional-StyleGAN. In this way, the latent codes are naturally clustered based on race information. Then we can generate a large amount of fake but diverse images with the same noise vector z but different races/labels, where we can generate a balanced training data pool for all classes. Ideally, we even do not need the Oracle or human labeling as the Conditional-StyleGAN provides samples with labels.
                </font>
            </p>
          </div>
        </div>
        <div class="flex-row-space-between">
          <div class="flex-item flex-column">
            <img class="image max-width-800" src="imgs/cgan.png">
            <p class="image-caption"><font size=2>Figure 4. Images generated by Conditional-StyleGAN with the same vector z and different labels</font></p>
          </div>
        </div>
        </div>
        <!--End Text with Images and Image buttons-->
        <div class="flex-row">
              <div class="flex-item flex-column">
                <h2 class="add-top-margin">References</h2>
                  <ol class="publication C-list">
                    <li>
                    <p class="text-small-margin">
                      Karras, Tero, Samuli Laine, and Timo Aila. "A style-based generator architecture for generative adversarial networks." Proceedings of the IEEE/CVF conference on computer vision and pattern recognition. 2019.
                    </p>
                  </li>
                    <li>
                    <p class="text-small-margin">
                      Karras, Tero, et al. "Analyzing and improving the image quality of stylegan." Proceedings of the IEEE/CVF conference on computer vision and pattern recognition. 2020.
                    </p>
                  </li>
                </ol>
              </div>
            </div>
    
      </div>
    </div>
  </div>
</body>

</html>